{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intoduction-to-Pandas\" data-toc-modified-id=\"Intoduction-to-Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intoduction to Pandas</a></span></li><li><span><a href=\"#Loading-and-working-with-data\" data-toc-modified-id=\"Loading-and-working-with-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading and working with data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixing-the-headers-with-re\" data-toc-modified-id=\"Fixing-the-headers-with-re-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Fixing the headers with <code>re</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-new-variable\" data-toc-modified-id=\"Creating-a-new-variable-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Creating a new variable</a></span></li><li><span><a href=\"#Plotting-in-pandas:-quick-and-easy\" data-toc-modified-id=\"Plotting-in-pandas:-quick-and-easy-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Plotting in pandas: quick and easy</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-about-plotting-a-profile?\" data-toc-modified-id=\"What-about-plotting-a-profile?-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>What about plotting a profile?</a></span></li></ul></li></ul></li><li><span><a href=\"#Indexing-with-pandas\" data-toc-modified-id=\"Indexing-with-pandas-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Indexing with <code>pandas</code></a></span></li><li><span><a href=\"#Running-means\" data-toc-modified-id=\"Running-means-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Running means</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy-way\" data-toc-modified-id=\"Numpy-way-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Numpy way</a></span></li><li><span><a href=\"#We-can-do-the-same-in-pandas\" data-toc-modified-id=\"We-can-do-the-same-in-pandas-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>We can do the same in pandas</a></span></li></ul></li><li><span><a href=\"#Binning-the-data-into-1m-bins\" data-toc-modified-id=\"Binning-the-data-into-1m-bins-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Binning the data into 1m bins</a></span><ul class=\"toc-item\"><li><span><a href=\"#Group-the-data-by-depth\" data-toc-modified-id=\"Group-the-data-by-depth-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Group the data by depth</a></span></li><li><span><a href=\"#Plot-the-number-of-measurements-for-each-depth.\" data-toc-modified-id=\"Plot-the-number-of-measurements-for-each-depth.-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Plot the number of measurements for each depth.</a></span></li><li><span><a href=\"#Plot-the-average-salinity-by-depth\" data-toc-modified-id=\"Plot-the-average-salinity-by-depth-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Plot the average salinity by depth</a></span></li></ul></li></ul></li><li><span><a href=\"#Wave-glider-data-+-ship-pCO2\" data-toc-modified-id=\"Wave-glider-data-+-ship-pCO2-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Wave glider data + ship <em>p</em>CO<sub>2</sub></a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Waveglider\" data-toc-modified-id=\"Waveglider-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Waveglider</a></span></li><li><span><a href=\"#Ship-data\" data-toc-modified-id=\"Ship-data-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Ship data</a></span></li></ul></li><li><span><a href=\"#Wave-Glider-data\" data-toc-modified-id=\"Wave-Glider-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Wave Glider data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot-Wave-Glider-track\" data-toc-modified-id=\"Plot-Wave-Glider-track-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Plot Wave Glider track</a></span></li><li><span><a href=\"#Plot-resampled--$\\-f$CO$_2$-time-series\" data-toc-modified-id=\"Plot-resampled--$\\-f$CO$_2$-time-series-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Plot resampled  $\\ f$CO$_2$ time-series</a></span></li><li><span><a href=\"#Time-series-subplots-of-temperature/salinity-and-pCO2\" data-toc-modified-id=\"Time-series-subplots-of-temperature/salinity-and-pCO2-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Time-series subplots of temperature/salinity and pCO2</a></span></li></ul></li><li><span><a href=\"#Ship-based-Underway-pCO2\" data-toc-modified-id=\"Ship-based-Underway-pCO2-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Ship-based Underway pCO2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot-ship-cruise-track\" data-toc-modified-id=\"Plot-ship-cruise-track-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Plot ship cruise track</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction to Pandas\n",
    "<div style=\"float:left; width:45%;\">\n",
    "<img src=\"../images/panda.gif\">\n",
    "</div>\n",
    "\n",
    "- Pandas is built on `numpy`\n",
    "- The main class you'll work with is called a `DataFrame` often abbreviated to `df`\n",
    "- If data has a column structure, it makes life a lot easier! You can call the column name using `df.Temperature`\n",
    "- Pandas read CSV and Excel files  \n",
    "- In this exercise we will learn how to read a CSV, do some basic stats, subset the data and then plot\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"clear:both; width:90%; margin-left:30px; margin-top: 100px;\">\n",
    "    Below is a cheat sheet from DataCamp\n",
    "    <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf\">\n",
    "        <img src='https://api.ning.com/files/C5oySLeJLWY1o*iHM1XzvVl*4GgdVb6RHvdGg3m0tGQSa9I4CeXVfkKcJ3Symm6jLi33fBq-d1K5VzxhTL7Z5ZMjuo6xhWj7/pandas.PNG'>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:36:53.777452Z",
     "start_time": "2018-03-13T08:36:52.845493Z"
    }
   },
   "outputs": [],
   "source": [
    "# equivalent to saying `from matplotlib.pylab import *`\n",
    "# but also ensures that plots are shown in the notebook\n",
    "%pylab inline  \n",
    "\n",
    "# the following are standard practice abbreviations for packages\n",
    "# I highly recommend that you follow these\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic structure of `pd.DataFrames` and `pd.Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:36:59.711495Z",
     "start_time": "2018-03-13T08:36:59.625950Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:37:47.087632Z",
     "start_time": "2018-03-13T08:37:47.073751Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and working with data\n",
    "Viewing the data, indexing etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:41:35.809924Z",
     "start_time": "2018-03-13T08:41:35.543266Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/CTD/01_SANAE53_CTD_007.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure [dbar]   ']  # use dictionary notation to access any header (returns a Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the headers with `re`\n",
    "\n",
    "**Are the headers broken? Why fix them?**  \n",
    "`pandas.DataFrame`s allow us to interactively call the data without using `dict`ionary notation `dict['key']`. We can simply use `df.varname`, but this only works if the headers are correctly formatted, with no `/`, `-`, `.`, etc.\n",
    "\n",
    "\n",
    "\n",
    "**`r`egular `e`xpressions** is a very powerful string manipulation tool\n",
    "we use it here to substitute all special characters\n",
    "The pattern below does the following:\n",
    "    \n",
    "     []  match any of the characters inside brackets\n",
    "      ^  doesn't match\n",
    "    A-Z  match upper case\n",
    "    a-z  match lower case\n",
    "    0-9  any digit\n",
    "      +  1 or more occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:39:44.258123Z",
     "start_time": "2018-03-13T08:39:44.252129Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '[^A-Za-z0-9]+'\n",
    "cols = [re.sub(pattern, '', c) for c in df.columns]\n",
    "print(cols)\n",
    "\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:43:02.804098Z",
     "start_time": "2018-03-13T08:43:02.797386Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Dates'] = np.datetime64('2010-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting in pandas: quick and easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:44:10.794439Z",
     "start_time": "2018-03-13T08:44:10.590394Z"
    }
   },
   "outputs": [],
   "source": [
    "df.t090C.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's plot dissolved oxygen column: `sbeox0ML/L`  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:55:22.485372Z",
     "start_time": "2018-03-13T08:55:22.281898Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sbeox0MLL'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about plotting a profile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:00:09.406442Z",
     "start_time": "2018-03-13T09:00:09.181280Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.plot.line(x='sbeox0MLL', y='depSM', figsize=[4, 6], ylim=[1000, 0], legend=False)\n",
    "ax.set_ylabel('test')\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with `pandas`\n",
    "\n",
    "1. Limit the data to the top 200 meters using the depth column. Note that it is best practice to use the `pd.Series.loc[row, col]` function. Look at the help of this function or read more about `pandas` indexing online: https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
    "2. Plot temperature by depth using pandas default plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:54:23.173733Z",
     "start_time": "2018-03-13T09:54:23.137190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df200 = 'dataframe limited to top 200m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:56:05.644683Z",
     "start_time": "2018-03-13T09:56:05.434206Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df200.plot(x='flECOAFL', y='depSM', \n",
    "           figsize=[4, 6], \n",
    "           ylim=[220, 0], \n",
    "           xlim=[-.2, 1.2],\n",
    "           title='CTD Fluorescence', \n",
    "           legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running means\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*gRzEgnmJgUYYsuwOKzPpAw.png\">\n",
    "\n",
    "Smooth the data according to the rolling mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:05:06.214553Z",
     "start_time": "2018-03-13T10:05:06.081584Z"
    }
   },
   "outputs": [],
   "source": [
    "window = 600\n",
    "flr = df200['flECOAFL'].values\n",
    "flr_mv_avg = np.zeros_like(flr) * np.nan\n",
    "\n",
    "for i0 in range(df200.shape[0] - window): \n",
    "    i1 = i0 + window\n",
    "    j = int(i0 + window / 2)\n",
    "    flr_mv_avg[j] = flr[i0:i1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:05:33.645463Z",
     "start_time": "2018-03-13T10:05:33.319547Z"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=[9, 4])\n",
    "plot(flr, lw=4)\n",
    "plot(flr_mv_avg, lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:13:38.532673Z",
     "start_time": "2018-03-13T10:13:38.528072Z"
    }
   },
   "outputs": [],
   "source": [
    "flr = df200['flECOAFL']\n",
    "roll = flr.rolling(window=600, center=True)  # create a rolling window object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:16:28.846471Z",
     "start_time": "2018-03-13T10:16:28.613169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a plot here that shows the measured, rolling mean and rolling median lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning the data into 1m bins\n",
    "\n",
    "The CTD samples at a much higher frequency than once per meter. This is not always useful.  \n",
    "We can bin the CTD data using pandas using the groupby function\n",
    "\n",
    "**Principle used in groupby**: \n",
    "Group together variables if they are the same. Then take the average, standard deviation, etc. of the groups.  \n",
    "For our specific case, the depths are not the same, but they could be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:24:55.637557Z",
     "start_time": "2018-03-13T10:24:55.435565Z"
    }
   },
   "outputs": [],
   "source": [
    "df.depSM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:27:39.424947Z",
     "start_time": "2018-03-13T10:27:39.418490Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Depth_bins'] = 'some function to make 1m bins; hint: we want the nearest metre'\n",
    "df['Depth_bins'] = df.depSM.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:28:29.939379Z",
     "start_time": "2018-03-13T10:28:29.925045Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Depth_bins.value_counts()  # shows the frequency of depth measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data by depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:36:50.256066Z",
     "start_time": "2018-03-13T10:36:50.249441Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grp = df.groupby(by='Depth_bins')  # Inspect the grp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:38:18.404545Z",
     "start_time": "2018-03-13T10:38:18.231574Z"
    }
   },
   "outputs": [],
   "source": [
    "dfm = grp.mean()  # mean per depth bin\n",
    "dfs = grp.std()  # standard deviation per depth bin\n",
    "\n",
    "x1 = (dfm.flECOAFL + dfs.flECOAFL * 1.5)\n",
    "x2 = (dfm.flECOAFL - dfs.flECOAFL * 1.5)\n",
    "y = dfm.index.values\n",
    "\n",
    "plt.figure(figsize=[4, 6])\n",
    "plt.fill_betweenx(y, x1, x2)\n",
    "ylim(200, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of measurements for each depth. \n",
    "\n",
    "What do you think the plot shows? Think about what a CTD-rosette does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T11:03:21.118133Z",
     "start_time": "2018-03-13T11:03:20.921288Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. create 10m bins by rounding \n",
    "# 2. group by the new index\n",
    "# 3. get the number of depths per bin\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the average salinity by depth\n",
    "\n",
    "again with x-axis as salinity and y-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T14:52:50.106935Z",
     "start_time": "2018-03-07T14:52:50.098025Z"
    }
   },
   "source": [
    "# Wave glider data + ship *p*CO<sub>2</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<a href=\"https://www.youtube.com/watch?v=fk-2XDIbZiQ\" title=\"Click for waveglider video\"><img src=\"http://defsec.csir.co.za/wp-content/uploads/2014/09/IMG_7760.jpg\" style=\"float:left; width:44%; margin-right:20px\"></a>\n",
    "### Waveglider\n",
    "The CSIR has a wave glider that measures surface partial pressure of CO<sub>2</sub> (pCO2). The wave glider is deployed in the Southern Ocean where it measures pCO2, temperature, salinity and pH every hour. \n",
    "\n",
    "### Ship data\n",
    "The Agulhas II also measures pCO2 in the Southern Ocean. However, this data is slightly different in structure. The raw files are not concatenated in one simple directory as you'd like :-/  \n",
    "Your job is to use pandas to load and concatenate these files, then plot the data on a map. \n",
    "\n",
    "  \n",
    " \n",
    "\n",
    "Again... \n",
    "\n",
    "1. Where? (lat and lon)\n",
    "2. When? (line graphs)\n",
    "3. What? (line graphs of pCO2 with other variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave Glider data\n",
    "\n",
    "inspect the data first. I've created a custom function that makes this a lot easier (shows the first 200 lines of the file with line numbers). This lets you inspect the structure of the file. This is critical to knowing how we should import the file - what settings we should pass to `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%less_n ../data/WaveGlider/02_wave_glider.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:41:18.742509Z",
     "start_time": "2018-03-13T12:41:18.720705Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the keyword arguements available to pd.read_csv. Look specifically at index_col= and parse_dates=, \n",
    "\n",
    "fname = '../data/WaveGlider/02_wave_glider.csv'\n",
    "df = pd.read_csv(fname, comment='#', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Wave Glider track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot resampled  $\\ f$CO$_2$ time-series \n",
    "\n",
    "If we have an index that is `np.datetime64` we can resample the data at different intervals. This is done with the `pd.DataFrame.resample` function. This creates a `resample` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:58:55.142499Z",
     "start_time": "2018-03-13T12:58:54.909578Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hr = df.copy()\n",
    "df_6H = df_hr.resample('6H')  # creates a resample object that has methods\n",
    "\n",
    "df_hr.DeltaFco2_filled.plot()\n",
    "df_6H.DeltaFco2_filled.median().plot()\n",
    "plt.show()\n",
    "\n",
    "# Try this for several other time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series subplots of temperature/salinity and pCO2\n",
    "\n",
    "Create a plot that looks like this, with your own colors etc. \n",
    "\n",
    "![](../images/WaveGlider_timeseries.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ship-based Underway pCO2\n",
    "\n",
    "The Ship-based pCO2 that you'll be using is raw data and has not been prepared as the wave glider data has. This means it requires a bit more processing. You'll need to do a bit of work to read in the files and concatenate them. \n",
    "\n",
    "You can also, if you want, fix the column headers so that there are only alpha-numerical characters in the column names.\n",
    "\n",
    "**Measurement `Type`**  \n",
    "Because it is still raw the data contains oceanic and atmospheric measurements. These are denoted by the `Type` column, where `EQU` is the equilibrator measurement from seawater, and `ATM` is the atmospheric measurement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%less_n ../data/ShipCO2/CSIR GO8050_347-0000dat.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:21:46.367690Z",
     "start_time": "2018-03-13T13:21:45.337069Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "flist = glob('../data/ShipCO2/*dat.txt')\n",
    "\n",
    "data = []\n",
    "for fname in flist:\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname, \n",
    "                     # <-- seperator to tabs\n",
    "                     # <-- DateTime as the index column which we create in the next line\n",
    "                     parse_dates={'DateTime': ['Date', 'PC Time']},  # create a new column as DATE. \n",
    "                    )\n",
    "    data.append(df)\n",
    "    \n",
    "#HINT: \n",
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:23:35.298975Z",
     "start_time": "2018-03-13T13:23:35.206377Z"
    }
   },
   "outputs": [],
   "source": [
    "co2  # data is imported with dates as the initial column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:25:28.078723Z",
     "start_time": "2018-03-13T13:25:27.875163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Type column shows if data is equilibrator (EQU), atmospheric (ATM)\n",
    "# or standard calibration gasses (STDx). We are interested only in the EQU\n",
    "\n",
    "# get the boolean index for only EQU values\n",
    "i = co2.Type == 'EQU'\n",
    "j = co2.Type == 'ATM'\n",
    "\n",
    "# use .loc (index function) to get CO2 column and EQU values\n",
    "co2_EQU = co2.loc[i, 'CO2 um/m']  \n",
    "co2_ATM = co2.loc[j, 'CO2 um/m']  \n",
    "\n",
    "co2_EQU.plot()\n",
    "co2_ATM.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:16:57.467071Z",
     "start_time": "2018-03-13T13:16:57.272054Z"
    }
   },
   "source": [
    "### Plot ship cruise track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
