{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intoduction-to-Pandas\" data-toc-modified-id=\"Intoduction-to-Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intoduction to Pandas</a></span></li><li><span><a href=\"#Loading-and-working-with-data\" data-toc-modified-id=\"Loading-and-working-with-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading and working with data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixing-the-headers-with-re\" data-toc-modified-id=\"Fixing-the-headers-with-re-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Fixing the headers with <code>re</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-new-variable\" data-toc-modified-id=\"Creating-a-new-variable-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Creating a new variable</a></span></li><li><span><a href=\"#Plotting-in-pandas:-quick-and-easy\" data-toc-modified-id=\"Plotting-in-pandas:-quick-and-easy-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Plotting in pandas: quick and easy</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-about-plotting-a-profile?\" data-toc-modified-id=\"What-about-plotting-a-profile?-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>What about plotting a profile?</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise:-repeat-of-yesterday\" data-toc-modified-id=\"Exercise:-repeat-of-yesterday-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Exercise: repeat of yesterday</a></span></li><li><span><a href=\"#Running-means\" data-toc-modified-id=\"Running-means-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Running means</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy-way\" data-toc-modified-id=\"Numpy-way-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Numpy way</a></span></li><li><span><a href=\"#We-can-do-the-same-in-pandas\" data-toc-modified-id=\"We-can-do-the-same-in-pandas-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>We can do the same in pandas</a></span></li></ul></li><li><span><a href=\"#Binning-the-data-into-1m-bins\" data-toc-modified-id=\"Binning-the-data-into-1m-bins-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Binning the data into 1m bins</a></span><ul class=\"toc-item\"><li><span><a href=\"#Group-the-data-by-depth\" data-toc-modified-id=\"Group-the-data-by-depth-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Group the data by depth</a></span></li><li><span><a href=\"#Plot-the-number-of-measurements-for-each-depth.\" data-toc-modified-id=\"Plot-the-number-of-measurements-for-each-depth.-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Plot the number of measurements for each depth.</a></span></li><li><span><a href=\"#Plot-the-average-salinity-by-depth\" data-toc-modified-id=\"Plot-the-average-salinity-by-depth-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Plot the average salinity by depth</a></span></li></ul></li><li><span><a href=\"#Wave-glider-data-+-ship-pCO2\" data-toc-modified-id=\"Wave-glider-data-+-ship-pCO2-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Wave glider data + ship <em>p</em>CO<sub>2</sub></a></span><ul class=\"toc-item\"><li><span><a href=\"#Waveglider\" data-toc-modified-id=\"Waveglider-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Waveglider</a></span></li><li><span><a href=\"#Ship-data\" data-toc-modified-id=\"Ship-data-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Ship data</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction to Pandas\n",
    "<div style=\"float:left; width:45%;\">\n",
    "<img src=\"../images/panda.gif\">\n",
    "</div>\n",
    "\n",
    "- Pandas is built on `numpy`\n",
    "- The main class you'll work with is called a `DataFrame` often abbreviated to `df`\n",
    "- If data has a column structure, it makes life a lot easier! You can call the column name using `df.Temperature`\n",
    "- Pandas read CSV and Excel files  \n",
    "- In this exercise we will learn how to read a CSV, do some basic stats, subset the data and then plot\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"clear:both; width:90%; margin-left:30px; margin-top: 100px;\">\n",
    "    Below is a cheat sheet from DataCamp\n",
    "    <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf\">\n",
    "        <img src='../images/pandas_cheat_sheet.png'>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:36:53.777452Z",
     "start_time": "2018-03-13T08:36:52.845493Z"
    }
   },
   "outputs": [],
   "source": [
    "# equivalent to saying `from matplotlib.pylab import *`\n",
    "# but also ensures that plots are shown in the notebook\n",
    "%pylab inline  \n",
    "\n",
    "# the following are standard practice abbreviations for packages\n",
    "# I highly recommend that you follow these\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic structure of `pd.DataFrames` and `pd.Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:36:59.711495Z",
     "start_time": "2018-03-13T08:36:59.625950Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:37:47.087632Z",
     "start_time": "2018-03-13T08:37:47.073751Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and working with data\n",
    "Viewing the data, indexing etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:41:35.809924Z",
     "start_time": "2018-03-13T08:41:35.543266Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/CTD/01_SANAE53_CTD_007.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure [dbar]   ']  # use dictionary notation to access any header (returns a Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the headers with `re`\n",
    "\n",
    "**Are the headers broken? Why fix them?**  \n",
    "`pandas.DataFrame`s allow us to interactively call the data without using `dict`ionary notation `dict['key']`. We can simply use `df.varname`, but this only works if the headers are correctly formatted, with no `/`, `-`, `.`, etc.\n",
    "\n",
    "\n",
    "\n",
    "**`r`egular `e`xpressions** is a very powerful string manipulation tool\n",
    "we use it here to substitute all special characters\n",
    "The pattern below does the following:\n",
    "    \n",
    "     []  match any of the characters inside brackets\n",
    "      ^  doesn't match\n",
    "    A-Z  match upper case\n",
    "    a-z  match lower case\n",
    "    0-9  any digit\n",
    "      +  1 or more occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:39:44.258123Z",
     "start_time": "2018-03-13T08:39:44.252129Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = '[^A-Za-z0-9]+'\n",
    "cols = [re.sub(pattern, '', c) for c in df.columns]\n",
    "print(cols)\n",
    "\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:43:02.804098Z",
     "start_time": "2018-03-13T08:43:02.797386Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Dates'] = np.datetime64('2010-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting in pandas: quick and easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:44:10.794439Z",
     "start_time": "2018-03-13T08:44:10.590394Z"
    }
   },
   "outputs": [],
   "source": [
    "df.t090C.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's plot dissolved oxygen column: `sbeox0ML/L`  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:55:22.485372Z",
     "start_time": "2018-03-13T08:55:22.281898Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sbeox0MLL'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about plotting a profile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:00:09.406442Z",
     "start_time": "2018-03-13T09:00:09.181280Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.plot.line(x='sbeox0MLL', y='depSM', figsize=[4, 6], ylim=[1000, 0], legend=False)\n",
    "ax.set_ylabel('test')\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: repeat of yesterday\n",
    "\n",
    "1. Limit the data to the top 200 meters\n",
    "2. Plot temperature by depth using pandas default plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:54:23.173733Z",
     "start_time": "2018-03-13T09:54:23.137190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = df.depSM < 200\n",
    "print(idx)\n",
    "print(idx.sum())\n",
    "df200 = df[idx]\n",
    "print(df200.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T09:56:05.644683Z",
     "start_time": "2018-03-13T09:56:05.434206Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df200.plot(x='flECOAFL', y='depSM', \n",
    "           figsize=[4, 6], \n",
    "           ylim=[220, 0], \n",
    "           xlim=[-.2, 1.2],\n",
    "           title='CTD Fluorescence', \n",
    "           legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running means\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*gRzEgnmJgUYYsuwOKzPpAw.png\">\n",
    "\n",
    "Smooth the data according to the rolling mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:05:06.214553Z",
     "start_time": "2018-03-13T10:05:06.081584Z"
    }
   },
   "outputs": [],
   "source": [
    "window = 600\n",
    "flr = df200['flECOAFL'].values\n",
    "flr_mv_avg = np.zeros_like(flr) * np.nan\n",
    "\n",
    "for i0 in range(df200.shape[0] - window): \n",
    "    i1 = i0 + window\n",
    "    j = int(i0 + window / 2)\n",
    "    flr_mv_avg[j] = flr[i0:i1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:05:33.645463Z",
     "start_time": "2018-03-13T10:05:33.319547Z"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=[9, 4])\n",
    "plot(flr, lw=4)\n",
    "plot(flr_mv_avg, lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:13:38.532673Z",
     "start_time": "2018-03-13T10:13:38.528072Z"
    }
   },
   "outputs": [],
   "source": [
    "flr = df200['flECOAFL']\n",
    "roll = flr.rolling(window=600, center=True)  # create a rolling window object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:16:28.846471Z",
     "start_time": "2018-03-13T10:16:28.613169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a plot here that shows the measured, rolling mean and rolling median lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning the data into 1m bins\n",
    "\n",
    "The CTD samples at a much higher frequency than once per meter. This is not always useful.  \n",
    "We can bin the CTD data using pandas using the groupby function\n",
    "\n",
    "**Principle used in groupby**: \n",
    "Group together variables if they are the same. Then take the average, standard deviation, etc. of the groups.  \n",
    "For our specific case, the depths are not the same, but they could be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:24:55.637557Z",
     "start_time": "2018-03-13T10:24:55.435565Z"
    }
   },
   "outputs": [],
   "source": [
    "df.depSM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:27:39.424947Z",
     "start_time": "2018-03-13T10:27:39.418490Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Depth_bins'] = 'some function to make 1m bins; hint: we want the nearest metre'\n",
    "df['Depth_bins'] = df.depSM.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:28:29.939379Z",
     "start_time": "2018-03-13T10:28:29.925045Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Depth_bins.value_counts()  # shows the frequency of depth measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data by depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:36:50.256066Z",
     "start_time": "2018-03-13T10:36:50.249441Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grp = df.groupby(by='Depth_bins')  # Inspect the grp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:38:18.404545Z",
     "start_time": "2018-03-13T10:38:18.231574Z"
    }
   },
   "outputs": [],
   "source": [
    "dfm = grp.mean()  # mean per depth bin\n",
    "dfs = grp.std()  # standard deviation per depth bin\n",
    "\n",
    "x1 = (dfm.flECOAFL + dfs.flECOAFL * 1.5)\n",
    "x2 = (dfm.flECOAFL - dfs.flECOAFL * 1.5)\n",
    "y = dfm.index.values\n",
    "\n",
    "plt.figure(figsize=[4, 6])\n",
    "plt.fill_betweenx(y, x1, x2)\n",
    "ylim(200, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of measurements for each depth. \n",
    "\n",
    "What do you think the plot shows? Think about what a CTD-rosette does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T11:03:21.118133Z",
     "start_time": "2018-03-13T11:03:20.921288Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Depth_bins_10'] = df.depSM.round(-1)  # create 10m bins by rounding \n",
    "grp10 = df.groupby('Depth_bins_10')  # group by the new index\n",
    "count = grp10.depSM.count()  # get the number of depths per bin\n",
    "count.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the average salinity by depth\n",
    "\n",
    "again with x-axis as salinity and y-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T14:52:50.106935Z",
     "start_time": "2018-03-07T14:52:50.098025Z"
    }
   },
   "source": [
    "## Wave glider data + ship *p*CO<sub>2</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.youtube.com/watch?v=fk-2XDIbZiQ\" title=\"Click for waveglider video\"><img src=\"http://defsec.csir.co.za/wp-content/uploads/2014/09/IMG_7760.jpg\" style=\"float:left; width:44%; margin-right:20px\"></a>\n",
    "### Waveglider\n",
    "The CSIR has a wave glider that measures surface partial pressure of CO<sub>2</sub> (pCO2). The wave glider is deployed in the Southern Ocean where it measures pCO2, temperature, salinity and pH every hour. \n",
    "\n",
    "### Ship data\n",
    "The Agulhas II also measures pCO2 in the Southern Ocean. However, this data is slightly different in structure. The raw files are not concatenated in one simple directory as you'd like :-/  \n",
    "Your job is to use pandas to load and concatenate these files, then plot the data on a map. \n",
    "\n",
    "  \n",
    "  \n",
    "In the homework you will be working with this data. Your task is to plot the data and try to see what's going on.\n",
    "\n",
    "Again... \n",
    "\n",
    "1. Where? (lat and lon)\n",
    "2. When? (line graphs)\n",
    "3. What? (line graphs of pCO2 with other variables)\n",
    "\n",
    "The file is named [./surface_pCO2_exercise2.py](./surface_pCO2_exercise2.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:41:18.742509Z",
     "start_time": "2018-03-13T12:41:18.720705Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = './02_exercise/02_wave_glider.csv'\n",
    "df = pd.read_csv(fname, \n",
    "                 comment='#', \n",
    "                 index_col='DateTime', \n",
    "                 parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:42:11.194338Z",
     "start_time": "2018-03-13T12:42:10.953820Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Temperature.plot(ylim=[6, 14], figsize=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:58:55.142499Z",
     "start_time": "2018-03-13T12:58:54.909578Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hr = df\n",
    "df_1D = df_hr.resample('1D').median()\n",
    "df_5D = df_hr.resample('5D').median()\n",
    "\n",
    "df_5D.DeltaFco2_filled.plot(lw=4, zorder=5)\n",
    "df_hr.DeltaFco2_filled.plot(lw=4, zorder=2)\n",
    "df_1D.DeltaFco2_filled.plot(lw=4, zorder=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:04:11.769809Z",
     "start_time": "2018-03-13T13:04:11.748504Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = df.reset_index().DateTime.astype(str)\n",
    "dt.str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:01:55.840168Z",
     "start_time": "2018-03-13T13:01:55.834009Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:58:04.511340Z",
     "start_time": "2018-03-13T12:58:04.313687Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df_5D.index.values  # .values gets numpy.ndarray of the index\n",
    "x = x.astype('O')\n",
    "y = df_5D.DeltaFco2_filled.values\n",
    "\n",
    "\n",
    "\n",
    "plt.plot_date(x, y, ms=0, lw=4, ls='-')\n",
    "plt.xticks(rotation=45)\n",
    "df_hr.DeltaFco2_filled.plot(lw=4)\n",
    "df_1D.DeltaFco2_filled.plot(lw=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:21:46.367690Z",
     "start_time": "2018-03-13T13:21:45.337069Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "flist = glob('./02_exercise/02_ship_data/*dat.txt')\n",
    "\n",
    "data = []\n",
    "for fname in flist:\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname, \n",
    "                     sep='\\t',  # set the seperator to tabs\n",
    "                     parse_dates={'DATE': ['Date', 'PC Time']},  # create a new column as DATE. \n",
    "                     # Pandas date parser will try to concat the two columns and read in the dates\n",
    "                     index_col='DATE',  # set the index as the index column\n",
    "                     skipinitialspace=True,  # ignore the blank spaces after each comma (for nice column names)\n",
    "                    )\n",
    "    data.append(df)\n",
    "    \n",
    "co2 = pd.concat(data, ignore_index=False)  # concatenate all the imported csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:23:35.298975Z",
     "start_time": "2018-03-13T13:23:35.206377Z"
    }
   },
   "outputs": [],
   "source": [
    "co2  # data is imported with dates as the initial column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:25:28.078723Z",
     "start_time": "2018-03-13T13:25:27.875163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Type column shows if data is equilibrator (EQU), atmospheric (ATM)\n",
    "# or standard calibration gasses (STDx). We are interested only in the EQU\n",
    "\n",
    "# get the boolean index for only EQU values\n",
    "i = co2.Type == 'EQU'\n",
    "j = co2.Type == 'ATM'\n",
    "\n",
    "# use .loc (index function) to get CO2 column and EQU values\n",
    "co2_EQU = co2.loc[i, 'CO2 um/m']  \n",
    "co2_ATM = co2.loc[j, 'CO2 um/m']  \n",
    "\n",
    "co2_EQU.plot()\n",
    "co2_ATM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T13:16:57.467071Z",
     "start_time": "2018-03-13T13:16:57.272054Z"
    }
   },
   "outputs": [],
   "source": [
    "co2.plot(y='latitude', x='longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cheat_sheet](https://api.ning.com/files/C5oySLeJLWY1o*iHM1XzvVl*4GgdVb6RHvdGg3m0tGQSa9I4CeXVfkKcJ3Symm6jLi33fBq-d1K5VzxhTL7Z5ZMjuo6xhWj7/pandas.PNG)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
